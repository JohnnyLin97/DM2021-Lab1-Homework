{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Information Name:林孮瑋\n",
    "\n",
    "Student ID:110062665\n",
    "\n",
    "GitHub ID:JohnnyLin97\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM2021-Lab1-master Repo](https://github.com/fhcalderon87/DM2021-Lab1-master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2021-Lab1-master Repo](https://github.com/fhcalderon87/DM2021-Lab1-master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fhcalderon87/DM2021-Lab1-master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 4th 11:59 pm, Thursday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part.1 Take Home Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 2      \n",
    "Experiment with other querying techniques using pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this cell complete the same task as lab1-master\"\"\"\n",
    "\n",
    "# data preparation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "import pandas as pd\n",
    "import helpers.data_mining_helpers as dmh\n",
    "\n",
    "\n",
    "# converting to pandas dataframe and adding columns\n",
    "df = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])\n",
    "df['category'] = twenty_train.target\n",
    "df['category_name'] = df.category.apply(lambda t: dmh.format_labels(t, twenty_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  category category_name\n",
      "103  From: mrb@cbnewsj.cb.att.com (m..bruncati) Sub...         2       sci.med\n",
      "109  From: nyeda@cnsvax.uwec.edu (David Nye) Subjec...         2       sci.med\n",
      "111  From: geb@cs.pitt.edu (Gordon Banks) Subject: ...         2       sci.med\n",
      "115  Subject: \"STAR GARTDS\" <sp?> Info wanted From:...         2       sci.med\n",
      "117  From: geb@cs.pitt.edu (Gordon Banks) Subject: ...         2       sci.med\n",
      "118  From: rogers@calamari.hi.com (Andrew Rogers) S...         2       sci.med\n",
      "121  From: cash@convex.com (Peter Cash) Subject: Re...         2       sci.med\n",
      "123  From: david@stat.com (David Dodell) Subject: H...         2       sci.med\n",
      "126  From: rousseaua@immunex.com Subject: Re: Barbe...         2       sci.med\n",
      "132  From: kxgst1+@pitt.edu (Kenneth Gilbert) Subje...         2       sci.med\n",
      "134  From: geb@cs.pitt.edu (Gordon Banks) Subject: ...         2       sci.med\n",
      "135  From: wcsbeau@alfred.carleton.ca (OPIRG) Subje...         2       sci.med\n",
      "136  From: jim.zisfein@factory.com (Jim Zisfein)  S...         2       sci.med\n",
      "139  From: hrubin@pop.stat.purdue.edu (Herman Rubin...         2       sci.med\n",
      "141  From: geb@cs.pitt.edu (Gordon Banks) Subject: ...         2       sci.med\n",
      "142  From: lady@uhunix.uhcc.Hawaii.Edu (Lee Lady) S...         2       sci.med\n",
      "145  From: todamhyp@charles.unlv.edu (Brian M. Huey...         2       sci.med\n",
      "148  From: lindae@netcom.com Subject: Friend Needs ...         2       sci.med\n",
      "149  From: 880506s@dragon.acadiau.ca (James R. Skin...         2       sci.med\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-28c85247b1e5>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(df.loc[100:150][filt])\n"
     ]
    }
   ],
   "source": [
    "# search category of \"sci.med\" from index 100 to 150\n",
    "filt = (df['category_name'] == 'sci.med')\n",
    "print(df.loc[100:150][filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the numbers of duplicate values\n",
    "df.duplicated('text')\n",
    "df.shape[0] - df.drop_duplicates(['text']).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
